{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérience 1, 2 et 3 avec les embeddings de NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats, spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderPath = \"embdFiles/\"\n",
    "nf_file = 'not_fake_'\n",
    "f_file = \"fake_\"\n",
    "endN = \"_NOUN.txt\"\n",
    "listNouns = ['article','beard','blood','company','death','gun','id','interview','passport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here is a test to see if it is possible compute easily with numpy the average point for one dataset\n",
    "path = folderPath + f_file + 'gun' + endN\n",
    "arr = np.genfromtxt(path,delimiter=' ',dtype='float32')\n",
    "avg = np.average(arr,axis=0)\n",
    "avg.shape\n",
    "#...of course it is possible, numpy can do everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour chaque nom, on recupère les datasets avec et sans fake devant le nom dans un numpy array, et on stocke tout dans une liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for article\n",
      "done for beard\n",
      "done for blood\n",
      "done for company\n",
      "done for death\n",
      "done for gun\n",
      "done for id\n",
      "done for interview\n",
      "done for passport\n"
     ]
    }
   ],
   "source": [
    "arrF_list = []\n",
    "arrNF_list = []\n",
    "for noun in listNouns:\n",
    "    fPath = folderPath + f_file + noun + endN\n",
    "    nfPath = folderPath + nf_file + noun + endN\n",
    "    arrF = np.genfromtxt(fPath,delimiter=' ',dtype='float32')\n",
    "    arrNF = np.genfromtxt(nfPath,delimiter=' ',dtype='float32')\n",
    "    arrF_list.append(arrF)\n",
    "    arrNF_list.append(arrNF)\n",
    "    print(\"done for \"+noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour chaque nom, on calcule le point moyen, dans les deux cas. On stocke les points moyens dans des arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgX_F = np.zeros((9,1024),dtype='float32')\n",
    "avgX_NF = np.zeros((9,1024),dtype='float32')\n",
    "avgX_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    avgF = np.average(arrF_list[i],axis=0)\n",
    "    avgNF = np.average(arrNF_list[i],axis=0)\n",
    "    avgX_F[i] = avgF\n",
    "    avgX_NF[i] = avgNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04823099, -0.14354958, -0.01562697, ...,  0.01719081,\n",
       "        -0.9936313 , -0.28639677],\n",
       "       [-0.23168902, -0.30192888,  0.55367124, ...,  0.28872445,\n",
       "        -0.15094164, -0.05723162],\n",
       "       [ 0.23994008,  0.46857274,  0.6180047 , ..., -1.0538108 ,\n",
       "         0.0454229 ,  0.0396353 ],\n",
       "       ...,\n",
       "       [-0.13170321, -0.27453583,  0.9930988 , ..., -0.5841659 ,\n",
       "        -0.19219185, -0.31720725],\n",
       "       [-0.16478896,  0.54115975, -0.07053245, ..., -0.5747151 ,\n",
       "        -1.0550352 , -1.4621655 ],\n",
       "       [-0.08293346, -0.015929  ,  0.19417278, ..., -0.5316996 ,\n",
       "        -0.3460909 , -0.02548151]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgX_F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour chaque nom, on récupère la liste des similarités cosinus entre le point moyen et chacun des points du dataset , et cela pour chacun des deux cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simf_list = []\n",
    "for i in range(9):\n",
    "    avg = avgX_F[i]\n",
    "    data = arrF_list[i]\n",
    "    n = len(data)\n",
    "    sim = np.zeros((n),dtype='float64')\n",
    "    for j in range(n):\n",
    "        sim[j] = 1-spatial.distance.cosine(data[j],avg) #1-distance pour avoir similarite\n",
    "    simf_list.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "simnf_list = []\n",
    "for i in range(9):\n",
    "    avg = avgX_NF[i]\n",
    "    data = arrNF_list[i]\n",
    "    n = len(data)\n",
    "    sim = np.zeros((n),dtype='float64')\n",
    "    for j in range(n):\n",
    "        sim[j] = 1-spatial.distance.cosine(data[j],avg) #1-distance pour avoir similarite\n",
    "    simnf_list.append(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérience 1 : étude de dispersion des embeddings de NOUN selon la présence de FAKE devant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On cherche ici a montrer si Fake a une influence ou pas sur la dispersion des points autour du point moyen. On va regarder la moyenne des similarités cosinus pour l'ensemble des noms, dans les deux cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par construire deux échantillons distincts, selon si le nom est précédé ou non de FAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fake = np.concatenate(simf_list)\n",
    "not_fake = np.concatenate(simnf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis calculons les moyennes pour les deux échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sf = np.average(fake)\n",
    "Snf = np.average(not_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8427543417241219 0.7565697389234177\n"
     ]
    }
   ],
   "source": [
    "print(Sf,Snf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On constate que la présence de Fake devant le nom augmente la similiarité avec le point moyen. Mais cette différence entre les deux cas est-elle significative ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifions l'égalité des variances des deux échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5633381012238198"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(fake)/np.var(not_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le rapport des deux variances est supérieur à 1/2 et inférieur à 2, on peut considérer l'égalité des variances. Passons maintenant au test de Student d'égalité des moyennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=21.488536412434197, pvalue=3.667909072774876e-102)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(fake,not_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La p-value est largement inférieure au risque de premier espèce qu'on fixe à 5%. Donc on peut considérer qu'il y a une différence **significative** entre les moyennes des deux échantillons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cette première expérience permet donc de conclure que la présence de Fake devant le nom diminue la dispersion des embeddings du nom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérience 2 : comparaison des similitudes entre les embeddings de NOUN précédé et non précédé par FAKE, selon l'usage sémantique de FAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On cherche à savoir si l'usage de FAKE a un impact sur la similarité entre le point moyen des embeddings de NOUN avec FAKE et le point moyen des embeddings sans FAKE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par définir les indexs des 3 principales catégories d'usage FAKE selon le nom auquel il est associé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['article','beard','blood','company','death','gun','id','interview','passport']\n",
    "inds_privatif = [1,2,3,4,5] #associé avec ces noms, FAKE prend un usage privatif\n",
    "inds_ambivalent = [6,8] #associé avec ces noms, FAKE prend un usage ambivalent\n",
    "inds_nonPrivatif = [0,7] #associé avec ces noms, FAKE prend un usage non-privatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les points moyens des embeddings ont déjà été calculés et stockés dans avgX_F et avgX_NF. Il ne reste qu'à calculer la similarité moyenne dans chacune des 3 catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "priv = np.zeros((len(inds_privatif)),dtype='float64')\n",
    "ambi = np.zeros((len(inds_ambivalent)),dtype='float64')\n",
    "nonp = np.zeros((len(inds_nonPrivatif)),dtype='float64')\n",
    "for i in range(len(priv)):\n",
    "    ind = inds_privatif[i]\n",
    "    priv[i] = 1- spatial.distance.cosine(avgX_F[ind],avgX_NF[ind])\n",
    "for i in range(len(ambi)):\n",
    "    ind = inds_ambivalent[i]\n",
    "    ambi[i] = 1- spatial.distance.cosine(avgX_F[ind],avgX_NF[ind])\n",
    "for i in range(len(nonp)):\n",
    "    ind = inds_nonPrivatif[i]\n",
    "    nonp[i] = 1- spatial.distance.cosine(avgX_F[ind],avgX_NF[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spriv = np.mean(priv)\n",
    "Sambi = np.mean(ambi)\n",
    "Snonp = np.mean(nonp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9078827977180481 0.9133485555648804 0.8935658931732178\n"
     ]
    }
   ],
   "source": [
    "print(Spriv,Sambi,Snonp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20525"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.concatenate([arrF_list[i] for i in inds_nonPrivatif]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10392"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arrNF_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selon l'hypothèse linguistique, on a supposé que le nom précédé de FAKE lorsqu'il était utilisé dans un usage non-privatif resterait davantage similaire au nom sans FAKE que lorsque FAKE était utilisé dans un usage ambivalent, et que l'usage ambivalent éloignait lui-même les deux formes du nom dans une moindre mesure que lorsque FAKE était employé privativement. En d'autres termes, on aurait supposé *Spriv < Sambi < Snonp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate ici que **ce n'est pas le cas**. L'usage de FAKE ne semble pas avoir d'influence sur l'éloignement des deux formes de NOUN avec ou sans FAKE. <br/><br/> **Notre hypothèse est donc rejetée**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérience 3 : étude de l'influence de l'usage de FAKE sur la variation de dispersion des embeddings de NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a montré dans l'expérience 1 que la présence de FAKE avant le nom réduisait la dispersion des embeddings de NOUN autour du point moyen. Maintenant, on se demande si la catégorie d'usage de FAKE a une influence sur la variation de dispersion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_priv = np.concatenate([simf_list[i] for i in inds_privatif])\n",
    "df_ambi = np.concatenate([simf_list[i] for i in inds_ambivalent])\n",
    "df_nonp = np.concatenate([simf_list[i] for i in inds_nonPrivatif])\n",
    "dnf_priv = np.concatenate([simnf_list[i] for i in inds_privatif])\n",
    "dnf_ambi = np.concatenate([simnf_list[i] for i in inds_ambivalent])\n",
    "dnf_nonp = np.concatenate([simnf_list[i] for i in inds_nonPrivatif])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit une fonction pour réaliser les Tests d'égalité de moyennes. On va en effet commencer par vérifier que, dans chaque catégorie, la présence de FAKE modifie bien la dispersion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testEgalMoyenne(arr1,arr2,alpha = 1e-3):\n",
    "    '''\n",
    "    Retourne False si la p-value du test de Student d'égalité de moyenne est inférieure au risque de premiere espece.\n",
    "    Cela signifie qu'il n'y a pas égalité des moyennes.\n",
    "    Sinon, retourne True et on ne peut rejeter l'hypothèse d'égalité des moyennes\n",
    "    '''\n",
    "    r = np.var(arr1)/np.var(arr2)\n",
    "    if r > 0.5 and r < 2 :\n",
    "        #pas d'egalite des variances\n",
    "        p = stats.ttest_ind(arr1,arr2,equal_var=True)[1]\n",
    "    else:\n",
    "        #pas d'egalite des variances\n",
    "        p = stats.ttest_ind(arr1,arr2,equal_var=False)[1]\n",
    "    if p > alpha:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "priv :  False\n",
      "\n",
      "ambi :  False\n",
      "\n",
      "nonp :  False\n"
     ]
    }
   ],
   "source": [
    "print('\\npriv : ',testEgalMoyenne(df_priv,dnf_priv))\n",
    "print('\\nambi : ',testEgalMoyenne(df_ambi,dnf_ambi))\n",
    "print('\\nnonp : ',testEgalMoyenne(df_nonp,dnf_nonp))\n",
    "#Si le test affiche FALSE c'est que les moyennes sont significativement différentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela ne fait que confirmer le résultat de l'expérience 1 appliqué cette fois uniquement au sein de chaque catégorie. Cela signifie que l'ont peut établir pour chaque catégorie un coefficient supérieur à 1 par lequel la similarité est multipliée lorsque le nom est précédé de FAKE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_priv = np.mean(df_priv)/np.mean(dnf_priv)\n",
    "coeff_ambi = np.mean(df_ambi)/np.mean(dnf_ambi)\n",
    "coeff_nonp = np.mean(df_nonp)/np.mean(dnf_nonp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'instar de l'hypothèse formulée lors de l'expérience 2, on pourrait formuler l'hypothèse suivante : <br/> L'usage de FAKE fait varier le coefficient de multiplication de la dispersion des embeddings de NOUN avec et sans FAKE. Soit (1) la privativité de FAKE augmente ce coefficient (c'est à dire que les embeddings sont dautant plus similaires que FAKE est privatif), soit (2) la privativité de FAKE fait diminuer ce coefficient (auquel cas la privativité de FAKE disperse davantage les embeddings). Autrement dit, on s'attend à : <br/> 1 - soit coeff_priv > coeff_ambi > coeff_nonp <br/> 2 - soit coeff_priv < coeff_ambi < coeff_nonp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1251746765628374 1.1401544722178965 1.0908976907793215\n"
     ]
    }
   ],
   "source": [
    "print(coeff_priv,coeff_ambi,coeff_nonp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09427108888349034, 0.10070390364848869, 0.07269134883473438)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df_priv)-np.mean(dnf_priv),np.mean(df_ambi)-np.mean(dnf_ambi),np.mean(df_nonp)-np.mean(dnf_nonp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On constate ici que de telles relations d'ordres n'existent pas sur les variations de dispersion des embeddings de NOUN. On ne peut donc pas conclure à l'influence du degré de privativité de FAKE sur la variation montrée à l'expérience 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérience 4, 5 et 6 sur les embeddings de FAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats, spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderPath = \"embdFiles/\"\n",
    "nf_file = 'not_fake_'\n",
    "f_file = \"fake_\"\n",
    "endF = \"_FAKE.txt\"\n",
    "listNouns = ['article','beard','blood','company','death','gun','id','interview','passport']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour chaque nom, on recupère les datasets des embeddings de FAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for article\n",
      "done for beard\n",
      "done for blood\n",
      "done for company\n",
      "done for death\n",
      "done for gun\n",
      "done for id\n",
      "done for interview\n",
      "done for passport\n"
     ]
    }
   ],
   "source": [
    "arr_list = []\n",
    "for noun in listNouns:\n",
    "    path = folderPath + f_file + noun + endF\n",
    "    arr = np.genfromtxt(path,delimiter=' ',dtype='float32')\n",
    "    arr_list.append(arr)\n",
    "    print(\"done for \"+noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On divise notre ensemble de données selon les catégories d'usage de FAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['article','beard','blood','company','death','gun','id','interview','passport']\n",
    "inds_privatif = [1,2,3,4,5] #associé avec ces noms, FAKE prend un usage privatif\n",
    "inds_ambivalent = [6,8] #associé avec ces noms, FAKE prend un usage ambivalent\n",
    "inds_nonPrivatif = [0,7] #associé avec ces noms, FAKE prend un usage non-privatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque ce sont **tous** des embeddings du même mot (FAKE), on peut se permettre de regrouper ensemble les embeddings d'une même catégorie d'usage sémantique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289 198 112\n"
     ]
    }
   ],
   "source": [
    "priv = np.concatenate([arr_list[i] for i in inds_privatif])\n",
    "ambi = np.concatenate([arr_list[i] for i in inds_ambivalent])\n",
    "nonp = np.concatenate([arr_list[i] for i in inds_nonPrivatif])\n",
    "print(len(priv),len(ambi),len(nonp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule le point moyen à chaque fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = np.average(priv,axis=0)\n",
    "Xa = np.average(ambi,axis=0)\n",
    "Xn = np.average(nonp,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rassemblons tout dans des listes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc_list = [Xp,Xa,Xn]\n",
    "usagesData = [priv,ambi,nonp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérience 4 : Etude des distances entre les embeddings des différentes catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'idée ici est de déterminer si les groupes d'embeddings de FAKE sont significativement éloignés les uns des autres selon l'usage de FAKE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cela, on va établir une distance moyenne des points d'une catégorie au barycentre de cette même catégorie, pour déterminer quel est \"l'écartement moyen\" d'un point au barycentre de sa catégorie. Cela permettra d'établir une boule ouverte de rayon moyen centrée sur le point moyen de la catégorie. On cherchera des inventuelles intersections de ces boules ouvertes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = spatial.distance.euclidean #cosine ou euclidean. Si on veut cosine similarity, penser a rajouter '1-' devant\n",
    "\n",
    "all_distances = []\n",
    "for i in range(3):\n",
    "    avg = Xc_list[i]\n",
    "    data = usagesData[i]\n",
    "    distances = np.zeros((len(data)),dtype='float64')\n",
    "    for j in range(len(data)):\n",
    "        distances[j] = metric(data[j],avg)\n",
    "    all_distances.append(distances)\n",
    "avg_distances = [np.mean(x) for x in all_distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.171789806194372, 10.900483437258789, 9.321767385516848]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On regarde alors si les boules ouvertes correspondant à deux catégories s'intersectent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ce calcul nécessite que le metric soit la distance euclidienne. Il suppose donc que l'espace vectoriel est euclidien\n",
    "#PS : de toute façon, avec cosine ou euclidean, le résultat est le même et les catégories s'intersectent mutuellement\n",
    "def intersection(i,j):\n",
    "    if metric != spatial.distance.euclidean:\n",
    "        print('Le metric utilisé doit être la distance euclidienne')\n",
    "        return\n",
    "    Xi = Xc_list[i]\n",
    "    Xj = Xc_list[j]\n",
    "    Di = avg_distances[i]\n",
    "    Dj = avg_distances[j]\n",
    "    DXs = metric(Xi,Xj)\n",
    "    print(Di,Dj,DXs)\n",
    "    if DXs > Di+Dj:\n",
    "        print(\"Catégories distinctes \\n\")\n",
    "    else:\n",
    "        print(\"Les catégories ont une intersection \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priv & nonp\n",
      "12.171789806194372 9.321767385516848 9.39514446258545\n",
      "Les catégories ont une intersection \n",
      "\n",
      "priv & ambi\n",
      "12.171789806194372 10.900483437258789 7.297373294830322\n",
      "Les catégories ont une intersection \n",
      "\n",
      "ambi & nonp\n",
      "10.900483437258789 9.321767385516848 7.865520477294922\n",
      "Les catégories ont une intersection \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('priv & nonp')\n",
    "intersection(0,2)\n",
    "print('priv & ambi')\n",
    "intersection(0,1)\n",
    "print('ambi & nonp')\n",
    "intersection(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusion de cette expérience* : toutes les catégories ont une intersection significatives entre elles. Cela signifie que la **différence d'usage de FAKE ne suffit pas à éloigner significativement les nuages de points de chaque catégorie**. Cependant, il n'est pas impossible de penser qu'il y a certaines dimensions parmi les 1024 dimensions de l'espace qui permettent de les distinguer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérience 5 : recherche de dimensions significativement différentes selon les catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'objectif ici est de tester l'hypothèse selon laquelle il existerait au moins une coordonnée par laquelle on pourrait significativement distinguer les embeddings de FAKE selon l'usage privatif, ambivalent ou non privatif. Pour cela, faisons l'hypothèse inverse : supposons qu'on veut montrer que la différence d'usage de FAKE ne PERMET PAS de distinguer les embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par créer la fonction qui réalise le test d'égalité de moyenne de Student entre deux arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testEgalMoyenne(arr1,arr2,alpha = 1e-3):\n",
    "    '''\n",
    "    Retourne False si la p-value du test de Student d'égalité de moyenne est inférieure au risque de premiere espece.\n",
    "    Cela signifie qu'il n'y a pas égalité des moyennes.\n",
    "    Sinon, retourne True et on ne peut rejeter l'hypothèse d'égalité des moyennes\n",
    "    '''\n",
    "    r = np.var(arr1)/np.var(arr2)\n",
    "    if r > 0.5 and r < 2 :\n",
    "        #pas d'egalite des variances\n",
    "        p = stats.ttest_ind(arr1,arr2,equal_var=True)[1]\n",
    "    else:\n",
    "        #pas d'egalite des variances\n",
    "        p = stats.ttest_ind(arr1,arr2,equal_var=False)[1]\n",
    "    if p > alpha:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On va donc créer une fonction qui comparera les 1024 coordonnées de deux distributions et l'appliquer à chaque paire de catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareMoy(arr1,arr2):\n",
    "    arr1T = np.transpose(arr1)\n",
    "    arr2T = np.transpose(arr2)\n",
    "    coords = []\n",
    "    for i in range(1024):\n",
    "        if not(testEgalMoyenne(arr1T[i],arr2T[i])):\n",
    "            coords.append(i)\n",
    "    if len(coords) > 0:\n",
    "        print('Il y a une différence significative de moyenne dans ',len(coords),\"dimensions\")\n",
    "    else:\n",
    "        print('On ne peut remarquer de différences significatives dans les 1024 dimensions entre ces deux catégories')\n",
    "    return(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "priv & nonp\n",
      "Il y a une différence significative de moyenne dans  669 dimensions\n",
      "\n",
      "priv & ambi\n",
      "Il y a une différence significative de moyenne dans  629 dimensions\n",
      "\n",
      "ambi & nonp\n",
      "Il y a une différence significative de moyenne dans  624 dimensions\n"
     ]
    }
   ],
   "source": [
    "print('\\npriv & nonp')\n",
    "comp_p_n = compareMoy(priv,nonp)\n",
    "print('\\npriv & ambi')\n",
    "comp_p_a = compareMoy(priv,ambi)\n",
    "print('\\nambi & nonp')\n",
    "comp_a_n = compareMoy(ambi,nonp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans chacune des trois comparaisons, on trouve approximativement 630 dimensions dans lesquelles les points moyens sont significativement différents. Cela ne garantie cependant pas que c'est uniquement le caractère privatif de FAKE qui explique ces 630 différences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La conclusion de ce test est seulement qu'on **peut rejeter l'hypothèse d'égalité des embeddings**. On comprend donc qu'au moins une des 630 dimensions permet(tent) de distinguer les embeddings de FAKE selon la catégorie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une intuition est de chercher dans les dimensions communes aux 3 comparaisons précédemment effectuées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   2,    7,   13,   20,   43,   52,   65,   74,   76,   85,   89,\n",
       "         93,   94,  105,  132,  140,  148,  152,  157,  159,  161,  162,\n",
       "        163,  172,  178,  191,  194,  199,  201,  203,  206,  208,  209,\n",
       "        220,  233,  236,  241,  247,  269,  276,  277,  283,  295,  301,\n",
       "        310,  327,  340,  342,  346,  349,  361,  364,  367,  383,  410,\n",
       "        419,  420,  427,  429,  448,  452,  462,  465,  468,  479,  480,\n",
       "        500,  501,  507,  509,  510,  518,  520,  525,  526,  531,  537,\n",
       "        538,  541,  542,  548,  557,  559,  565,  566,  571,  574,  575,\n",
       "        578,  579,  586,  587,  590,  596,  606,  611,  612,  616,  617,\n",
       "        618,  620,  622,  623,  625,  628,  636,  639,  642,  644,  652,\n",
       "        660,  664,  665,  670,  673,  674,  681,  687,  692,  693,  694,\n",
       "        695,  696,  701,  708,  711,  716,  718,  721,  722,  723,  724,\n",
       "        725,  726,  728,  731,  737,  738,  740,  741,  742,  745,  748,\n",
       "        753,  754,  757,  760,  763,  766,  767,  772,  774,  775,  777,\n",
       "        778,  780,  783,  787,  789,  790,  795,  797,  799,  802,  803,\n",
       "        816,  821,  826,  832,  833,  837,  840,  845,  846,  852,  856,\n",
       "        857,  858,  859,  860,  864,  865,  866,  868,  869,  872,  875,\n",
       "        878,  882,  883,  887,  889,  891,  897,  902,  903,  907,  908,\n",
       "        913,  914,  915,  917,  919,  920,  922,  926,  932,  933,  934,\n",
       "        938,  940,  944,  948,  949,  950,  951,  952,  953,  959,  961,\n",
       "        963,  972,  975,  976,  977,  985,  988,  992,  995, 1005, 1006,\n",
       "       1009, 1010, 1011, 1012, 1013, 1014, 1018, 1021])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = reduce(np.intersect1d,(comp_p_n,comp_p_a,comp_a_n))\n",
    "print(len(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est probable que la(les) dimension(s) permettant de discrimer les embeddings de FAKE selon son caractère privatif fasse(nt) partie des 239 dimensions de cette liste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience 6 : et si l'usage de FAKE changeait la dispersion des embeddings de FAKE lui-même ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On a montré dans l'expérience 3 que les différents usages de FAKE n'avaient pas d'influence sur la variation de dispersion des embeddings de NOUN avec et sans FAKE devant. Il n'a pas été possible de montrer dans les expériences 4 et 5 que l'usage de FAKE avait une influence sur la position des embeddings de FAKE. Cependant, on peut se demander s'il est posssible d'observer une variation de dispersion des embeddings de FAKE eux même selon la catégorie d'usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque nom, on calcule le point moyen.. On stocke les points moyens dans un array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgX = np.zeros((9,1024),dtype='float32')\n",
    "for i in range(9):\n",
    "    avg = np.average(arr_list[i],axis=0)\n",
    "    avgX[i] = avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule les similarités entre les embeddings et le point moyen pour chaque nom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_list = []\n",
    "for i in range(9):\n",
    "    avg = avgX[i]\n",
    "    data = arr_list[i]\n",
    "    n = len(data)\n",
    "    sim = np.zeros((n),dtype='float64')\n",
    "    for j in range(n):\n",
    "        sim[j] = 1-spatial.distance.cosine(data[j],avg) #1-distance pour avoir similarite\n",
    "    sim_list.append(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La liste *dist_list* contient donc les arrays des distances pour chaque nom. On va diviser cette liste selon les 3 catégories d'usage de FAKE et rassembler les arrays en un seul dans chaque catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "simPriv = np.concatenate([sim_list[i] for i in inds_privatif])\n",
    "simAmbi = np.concatenate([sim_list[i] for i in inds_ambivalent])\n",
    "simNonp = np.concatenate([sim_list[i] for i in inds_nonPrivatif])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintenant on fait les tests d'égalité des moyennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "priv & nonp :  False\n",
      "\n",
      "priv & ambi :  True\n",
      "\n",
      "ambi & nonp :  True\n"
     ]
    }
   ],
   "source": [
    "print('\\npriv & nonp : ',testEgalMoyenne(simPriv,simNonp))\n",
    "print('\\npriv & ambi : ',testEgalMoyenne(simPriv,simAmbi))\n",
    "print('\\nambi & nonp : ',testEgalMoyenne(simAmbi,simAmbi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On remarque que la seule différence notable de moyenne des similarités cosinus est celle entre l'usage privatif et non-privatif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il était intuitivement prévisible que la différence entre ces deux usages contradictoires serait plus importante. Observons les deux moyennes pour savoir dans lequel des deux cas la similarité entre les points est la plus importante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8143501916971174 0.8601295288119998\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(simPriv),np.mean(simNonp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On peut donc conclure que l'usage non-privatif de FAKE disperse moins les embeddings de FAKE que son usage privatif. Quant à l'usage ambivalent, on ne peut que supposer qu'il induirait un changement de dispersion intermédiaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8143501916971174  <  0.8229749735557672  <  0.8601295288119998\n"
     ]
    }
   ],
   "source": [
    "# On a bien une relation d'ordre ici\n",
    "print(np.mean(simPriv),' < ',np.mean(simAmbi),' < ',np.mean(simNonp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
